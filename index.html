<!-- Copyright: https://pengsida.net/ -->

<!doctype html>
<html>

<head>
<title>Liang Pan</title>

<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Liang Pan, The University of Hong Kong"> 
<meta name="description" content="Liang Pan's homepage">
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-137722442-1', 'auto');
  ga('send', 'pageview');
</script>

<!-- Show more content -->
<script type="text/javascript">
    function toggle_vis(id) {
        // var e = document.getElementById(id);
        var e = document.getElementsByClassName(id);
        var showText = document.getElementById("showText");
        for (var i = 0; i < e.length; i++) {
            if (e[i].style.display == "none") {
                e[i].style.display = "inline";
                showText.innerHTML = "[Show less]";
            } else {
                e[i].style.display = "none";
                showText.innerHTML = "[Show more]";
            }
        }
    }
</script>

<!-- Èº†Ê†áÊÇ¨ÂÅúÊòæÁ§∫ÂõæÁâá -->
<style>
    /* ÂÆπÂô®Ê†∑Âºè */
    .hover-container {
      position: relative;
      display: inline-block;
    }
  
    /* ÈªòËÆ§ÈöêËóèÂõæÁâá */
    .hover-image {
        display: none;
        position: absolute;
        bottom: 100%;  /* ÂõæÁâáÊòæÁ§∫Âú®ÊÇ¨ÂÅúÂÖÉÁ¥†‰∏äÊñπ */
        left: 125%;
        transform: translateX(-50%);
        z-index: 999;
        width: 200px;  /* Ëá™ÂÆö‰πâÂõæÁâáÂÆΩÂ∫¶ */
        border: 2px solid #ccc;
    }
  
    /* ÊÇ¨ÂÅúÊó∂ÊòæÁ§∫ÂõæÁâá */
    .hover-trigger:hover + .hover-image {
      display: block;
    }
  </style>

</head>

<body>

<div id="layout-content" style="margin-top:25px">


<table>
	<tbody>
		<tr>
			<td width="75%">
				<div id="toptitle">
					<h1>Liang Pan ÊΩò‰∫Æ<h1>
				</div>

                <h3 class="title">Building scalable AI agents with MLLMs and robots</h3>

				<p>
                    Incoming Ph.D. student</br>
                    School of Computing and Data Science</br>
                    The University of Hong Kong</br>
                    
                    <div class="hover-container">
                        Email: <a href="mailto:liangpan1005@163.com">liangpan1005@163.com</a> <b>|</b>
                        <span class="hover-trigger">WeChat: liangpan_time</span>
                        <img src="images/wechat_QRcode.jpg" class="hover-image" alt="ÊèêÁ§∫ÂõæÁâá">
                    </div> </br>

					</br>
                    [<a href="https://scholar.google.com/citations?user=B5rO1jcAAAAJ&hl=en" target="_blank">Google Scholar</a>][<a href="https://github.com/liangpan99" target="_blank">Github</a>][<a href="https://x.com/liangpan_t" target="_blank">X (Twitter)</a>][<a href="https://www.linkedin.com/in/liang-pan-1327612b7/" target="_blank">Linkedin</a>][CV]</br>

                </p>

			</td>
			<td width="25%">
				<img src="images/me.jpg" width="100%" style="border-radius: 10%;"/>
			</td>
		<tr>
	</tbody>
</table>

<h2>Biography</h2> 

<div style="display: flex">
    <p>
        I am an incoming CS Ph.D. student at The University of Hong Kong, advised by Prof. <a href="https://scholar.google.com/citations?user=TApLOhkAAAAJ&hl=en&oi=ao" target="_blank">Taku Komura</a>. 
        Prior that, I received my master's degree from Southeast University in 2024, advised by Prof. <a href="https://www.yangangwang.com/#me" target="_blank">Yangang Wang</a>.
    </p>
</div>

<div style="display: flex; margin-bottom: -10px">
    <p>
       üõ†Ô∏è Employment: <br>
        [2023/09‚Äî2025/06] Research Intern, Shanghai AI Laboratory, working closely with Dr. <a href="https://scholar.google.com/citations?user=GStTsxAAAAAJ&amp;hl=en&amp;oi=ao" target="_blank">Jingbo Wang</a>.  <br>
        [2023/03‚Äî2023/09] Research Intern, Xiaohongshu Inc., Mentor: <a href="https://haofanwang.github.io/" target="_blank">Haofan Wang</a>.
    </p>


</div>

<h2>News</h2>

<ul>
    <li>
      <div>
        [2025/04/21] Invited talks (<a href="https://www.dropbox.com/scl/fi/eqkcfqtex2s9qqcycwxsj/TokenHSI.pdf?rlkey=qfu74gpiyg6rlmj9n89pim9c5&e=1&st=lkaa1uuz&dl=0" target="_blank">slides</a>) on <em>"Towards Behavior Foundation Models of Human-Scene Interactions"</em> at <a href="https://www.ea.com/?setLocale=en-us" target="_blank">Electronic Arts</a> hosted by Dr. <a href="https://hungyuling.com/" target="_blank">Ben Ling</a>, <a href="https://anysyn3d.github.io/" target="_blank">AnySyn3D</a>, and <a href="https://mp.weixin.qq.com/s/A8-8EySNhhijblxg0vau1Q" target="_blank">Shanghai Computer Society</a>.
      </div>
    </li>
    <li>
      <div>[2025/04/05] TokenHSI has been selected as an oral paper at CVPR 2025. Top 3.3% of the accepted papers (96/2878).</div>
    </li>
    <li>
      <div>[2025/03/12] A brand-new version of SIMS is available. Enjoy the stories created by SIMS!</div>
    </li>
    <li>
        <div>[2025/02/27] TokenHSI got accepted by CVPR 2025.</div>
    </li>
    
    <div class="news" style="display:none">
    </div>
</ul>

<div class="show_button">
    <a href="javascript:toggle_vis('news')" id="showText">[Show more]</a>
</div>

<h2>
    Preprints
    <!-- <span style="font-size: 65%;">(* denotes equal contribution, and <span class="corresponding">‚Ä†</span> denotes the corresponding author)</span> -->
</h2>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/MOSPA.png">
    </div>
    <div class="publication_title">
      <p>
        üéßMOSPA: Human Motion Generation Driven by Spatial Audio</br>
        Shuyang Xu*, Zhiyang Dou*<span class="corresponding">‚Ä†</span>, Mingyi Shi, <b>Liang Pan</b>, Leo Ho, Jingbo Wang, Yuan Liu, Cheng Lin, Yuexin Ma, Wenping Wang<span class="corresponding">‚Ä†</span>, Taku Komura<span class="corresponding">‚Ä†</span></br>
        coming soon!
      </p>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/SIMS.jpg">
    </div>
    <div class="publication_title">
      <p>
        SIMS: Simulating Stylized Human-Scene Interactions with Retrieval-Augmented Script Generation</br>
        Wenjia Wang, <b>Liang Pan</b>, Zhiyang Dou, Jidong Mei, Zhouyingcheng Liao, Yuke Lou, Yifan Wu, Lei Yang, Jingbo Wang<span class="corresponding">‚Ä†</span>, Taku Komura<span class="corresponding">‚Ä†</span></br>
        [<a href="https://arxiv.org/abs/2411.19921" target="_blank">Paper</a>][<a href="https://wenjiawang0312.github.io/projects/sims/" target="_blank">Project Page</a>]
      </p>
    </div>
</div>

<div class="publication_container">
  <div class="publication_image">
      <img src="images/MotionStreamer.jpg">
  </div>
  <div class="publication_title">
    <p>
      Streaming Motion Generation via Diffusion-based Autoregressive Model in Causal Latent Space</br>
      Lixing Xiao,  Shunlin Lu,  Huaijin Pi,  Ke Fan,  <strong>Liang Pan</strong>,  Yueer Zhou, Ziyong Feng, Xiaowei Zhou,  Sida Peng<span class="corresponding">‚Ä†</span>,  Jingbo Wang</br>
      [<a href="https://arxiv.org/abs/2503.15451" target="_blank">Paper</a>][<a href="https://zju3dv.github.io/MotionStreamer/" target="_blank">Project Page</a>]
    </p>
  </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/ChatDyn.png">
    </div>
    <div class="publication_title">
      <p>
        ChatDyn: Language-Driven Multi-Actor Dynamics Generation in Street Scenes</br>
        Yuxi Wei, Jingbo Wang<span class="corresponding">‚Ä†</span>, Yuwen Du, Dingju Wang, <b>Liang Pan</b>, Chenxin Xu, Yao Feng, Bo Dai, Siheng Chen<span class="corresponding">‚Ä†</span></br>
        [<a href="https://arxiv.org/abs/2412.08685" target="_blank">Paper</a>][<a href="https://vfishc.github.io/chatdyn/" target="_blank">Project Page</a>]
      </p>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/PlugPlayMotionRefinement.png">
    </div>
    <div class="publication_title">
      <p>
        A Plug-and-Play Physical Motion Restoration Approach for In-the-Wild High-Difficulty Motions</br>
        Youliang Zhang*, Ronghui Li*, Yachao Zhang, <b>Liang Pan</b>, Jingbo Wang, Yebin Liu, Xiu Li<span class="corresponding">‚Ä†</span></br>
        [<a href="https://arxiv.org/abs/2412.17377" target="_blank">Paper</a>][<a href="https://physicalmotionrestoration.github.io/" target="_blank">Project Page</a>]
      </p>
    </div>
</div>

<h2>
    Publications
    <span style="font-size: 65%;">(* denotes equal contribution, and <span class="corresponding">‚Ä†</span> denotes the corresponding author)</span>
</h2>

<div class="newline_bg">
    <h3>2025</h3>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/TokenHSI.png">
    </div>
    <div class="publication_title">
      <p>
        TokenHSI: Unified Synthesis of Physical Human-Scene Interactions through Task Tokenization</br>
        <b>Liang Pan</b>, Zeshi Yang, Zhiyang Dou, Wenjia Wang, Buzhen Huang, Bo Dai, Taku Komura, Jingbo Wang<span class="corresponding">‚Ä†</span></br>
        CVPR 2025 <b><span style="color:#FF7777";>üèÜÔ∏è Oral Presentation (Top 3.3%)</span></b></br>
        The 1st Workshop on Humanoid Agents @ CVPR 2025 <b><span style="color:#FF7777";> Spotlight</span></b></br>
        [<a href="https://arxiv.org/abs/2503.19901" target="_blank">Paper</a>][<a href="https://liangpan99.github.io/TokenHSI/" target="_blank">Project Page</a>]
      </p>
    </div>
</div>

<div class="newline_bg">
    <h3>2024</h3>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/CloselyInteractiveHumans.jpg">
    </div>
    <div class="publication_title">
      <p>
        Closely Interactive Human Reconstruction with Proxemics and Physics-Guided Adaption</br>
        Buzhen Huang, Chen Li, Chongyang Xu, <b>Liang Pan</b>, Yangang Wang, Gim Hee Lee</br>
        CVPR 2024</br>
        [<a href="https://arxiv.org/abs/2404.11291" target="_blank">Paper</a>][<a href="https://github.com/boycehbz/HumanInteraction" target="_blank">Code</a>]
      </p>
    </div>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/InterScene.jpg">
    </div>
    <div class="publication_title">
      <p>
        Synthesizing Physically Plausible Human Motions in 3D Scenes</br>
        <b>Liang Pan</b>, Jingbo Wang, Buzhen Huang, Junyu Zhang, Haofan Wang, Xu Tang, Yangang Wang<span class="corresponding">‚Ä†</span></br>
        3DV 2024</br>
        [<a href="https://arxiv.org/abs/2308.09036" target="_blank">Paper</a>][<a href="https://liangpan99.github.io/InterScene/" target="_blank">Project Page</a>]
      </p>
    </div>
</div>


<div class="newline_bg">
    <h3>2022</h3>
</div>

<div class="publication_container">
    <div class="publication_image">
        <img src="images/NeuralMocon.jpg">
    </div>
    <div class="publication_title">
      <p>
        Neural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture</br>
        Buzhen Huang, <b>Liang Pan</b>, Yuan Yang, Jingyi Ju, Yangang Wang<span class="corresponding">‚Ä†</span></br>
        CVPR 2022</br>
        [<a href="https://arxiv.org/abs/2203.14065" target="_blank">Paper</a>][<a href="https://www.yangangwang.com/papers/HBZ-NM-2022-03.html" target="_blank">Project Page</a>]
      </p>
    </div>
</div>


</div>

</div>
</body>
</html>
